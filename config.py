# config.py - Model Router & Romanian-Aware Configuration
import streamlit as st
from typing import List, Dict, Any
from deep_translator import GoogleTranslator
import os
import random
import requests
from models import NarrativeResponse

class Config:
    """Central configuration with Romanian-optimized models"""

    PRIMARY_API_MODEL = "dumitrescustefan/bloom-1b1-romanian"
    FALLBACK_API_MODELS = [
        "microsoft/DialoGPT-medium",
        "facebook/xglm-564M",
        "bigscience/bloom-560m"
    ]
    LOCAL_MODEL = "EleutherAI/gpt-neo-1.3B"

    IMAGE_MODEL = "stabilityai/stable-diffusion-2-1"
    IMAGE_INTERVAL = 3
    IMAGE_NEGATIVE = "modern, cartoon, anime, text, watermark, lowres, blurry, extra limbs"
    

    @staticmethod
    def make_intro_text(scale: int) -> str:
        # PropoziÈ›ii istorice
        historical_sentences = [
            "Vlad ÈšepeÈ™, domnitor al ÈšÄƒrii RomÃ¢neÈ™ti, a condus cu o mÃ¢nÄƒ de fier Ã®ntre anii 1448 È™i 1476.",
            "CetÄƒÈ›ile de la poalele CarpaÈ›ilor au fost Ã®ntÄƒrite sub domnia lui, pentru a apÄƒra È›ara de invazii.",
            "Metodele sale dure i-au adus atÃ¢t respect, cÃ¢t È™i teamÄƒ Ã®n rÃ¢ndul duÈ™manilor È™i al supuÈ™ilor.",
            "TÃ¢rgoviÈ™te era inima puterii, locul unde deciziile puteau schimba soarta unui Ã®ntreg popor.",
            "Cronici vechi Ã®l descriu ca pe un strateg necruÈ›Äƒtor, dar drept."
        ]

        # PropoziÈ›ii legendare
        legendary_sentences = [
            "Se spune cÄƒ umbrele nopÈ›ii prindeau viaÈ›Äƒ Ã®n prezenÈ›a lui.",
            "BÄƒtrÃ¢nii È™optesc cÄƒ putea chema creaturi ascunse Ã®n bezna pÄƒdurilor.",
            "Legenda afirmÄƒ cÄƒ aerul se rÄƒcea brusc cÃ¢nd Vlad se mÃ¢nia.",
            "Unii credeau cÄƒ strÄƒvechi spirite Ã®l protejau Ã®n luptÄƒ.",
            "Se povesteÈ™te cÄƒ sÃ¢ngele duÈ™manilor Ã®i Ã®ntÄƒrea puterea."
        ]

        # TransformÄƒm scale Ã®ntr-un raport 0-1
        ratio = min(max(scale / 10.0, 0), 1)

        # NumÄƒr de propoziÈ›ii istorice vs legendare
        num_hist = max(1, int((1 - ratio) * 3))  
        num_leg = max(1, int(ratio * 3))         

        # Alegem propoziÈ›ii random
        chosen_hist = random.sample(historical_sentences, num_hist)
        chosen_leg = random.sample(legendary_sentences, num_leg)

        # Le mixÄƒm
        mixed_sentences = chosen_hist + chosen_leg
        random.shuffle(mixed_sentences)

        mixed_text = " ".join(mixed_sentences)

        # Intro narativ
        return (
        "Èšara RomÃ¢neascÄƒ, 1456. "
        + mixed_text
        + "\n\n"        
        )

    @staticmethod
    def build_dnd_prompt(story: List[Dict], character: Dict, legend_scale: int = 5) -> str:
        """ConstruieÈ™te prompt pentru LLM cu schema Pydantic integratÄƒ"""
        # Calcul raport legend vs istoric
        ratio = legend_scale / 10.0
        
        if ratio < 0.3:
            style_prefix = "Stil STRICT ISTORIC. FÄƒrÄƒ magie, fÄƒrÄƒ creaturi fantastice. "
        elif ratio > 0.7:
            style_prefix = "Stil LEGENDAR VAMPIRIC. Umbre, mister, folklore Ã®ntunecat. "
        else:
            style_prefix = "Stil echilibrat istoric È™i legendar. "
        
        # Context narativ
        context = "\n".join([f"{m['role'].upper()}: {m['text']}" for m in story[-4:]])
        
        # Info caracter
        char_info = (
            f"\n\nSTATISTICI CRITICE: ViaÈ›Äƒ={character['health']} | "
            f"ReputaÈ›ie={character['reputation']} | "
            f"LocaÈ›ie={character['location']} | "
            f"Galbeni={character.get('gold', 0)} | "
            f"Puterea ta este {'SLABÄ‚' if character['reputation'] < 30 else 'MEDIÄ‚' if character['reputation'] < 60 else 'CRESCUTÄ‚'}\n"
        )
        
        # RestricÈ›ii
        restrictions = ""
        if character['reputation'] < 20:
            restrictions = "JucÄƒtorul are reputaÈ›ie FOARTE JOSÄ‚. Este tratat cu suspiciune. Nu poate intra Ã®n audienÈ›Äƒ la boieri. "
        elif character['reputation'] < 50:
            restrictions = "JucÄƒtorul are reputaÈ›ie MEDIE. Poate interacÈ›iona cu negustori È™i soldaÈ›i, dar nu cu Ã®nalta nobilime. "
        else:
            restrictions = "JucÄƒtorul are reputaÈ›ie BUNÄ‚. Poate cere audienÈ›e, dar ÈšEPEÈ˜ este INACCESIBIL direct fÄƒrÄƒ motiv Ã®ntemeiat. "
        
        # Schema Pydantic
        schema = NarrativeResponse.model_json_schema()
        
        instructions = (
            f"\n{style_prefix}{restrictions}"            
            "REGULI OBLIGATORII:\n"
            "- 'narrative': 2-3 propoziÈ›ii, fÄƒrÄƒ greÈ™eli gramaticale, Ã®n romÃ¢nÄƒ medievalÄƒ\n"
            "- 'suggestions': ListÄƒ de EXACT 2-3 string-uri, fÄƒrÄƒ numere, fÄƒrÄƒ bullet points\n"
            "  EXEMPLU: [\"Cere audienÈ›Äƒ la curte.\", \"CautÄƒ informaÈ›ii Ã®n tÃ¢rg.\", \"Explorezi adÃ¢ncul pÄƒdurii.\"]\n"
            "- RespectÄƒ gramatica: 'unei pÄƒsÄƒri', 'unor boieri', nu 'unui pÄƒsÄƒri'\n"
            "VLAD ÈšEPEÈ˜ NU POATE FI ÃŽNVINS â€“ orice tentativÄƒ = game_over instant\n"
            "ReputaÈ›ia sub 20 = nu poÈ›i interacÈ›iona cu nobilii\n\n"
            f"RÄƒspunde STRICT Ã®n format JSON conform schemei:\n"
            f"STRICT JSON SCHEMA:\n"
            f"```json\n{schema}\n```\n"
        )
    
        return context + char_info + instructions
    
    @staticmethod
    def generate_image_prompt_llm(text: str, location: str) -> str:
        """GenereazÄƒ prompt pentru Stable Diffusion folosind LLM"""
        token = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY", "")
        if not token:
            return Config.generate_image_prompt(text, location)

        system = (
            "You are an assistant that writes short, highly detailed prompts "
            "for Stable-Diffusion in English. "
            "Include: time of day, number of people, context, weather, camera angle, lighting style. "
            "Keep it under 200 characters. DO NOT include object names like 'candle'. "
            "Describe LIGHTING EFFECTS only: 'warm dim lighting', 'soft glow', 'moonlight'."
        )

        user = (
            f"Story fragment: {text}\n"
            f"Exact place: {location}\n"
            "Write one English Stable-Diffusion prompt with lighting effects, no objects."
        )

        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ],
            "temperature": 0.75,
            "max_tokens": 60,
            "stream": False
        }

        try:
            r = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json"
                },
                json=payload,
                timeout=15
            )
            r.raise_for_status()
            llm_prompt = r.json()["choices"][0]["message"]["content"].strip()
            llm_prompt = llm_prompt.replace('"', '')
            if llm_prompt.endswith('.'):
                llm_prompt = llm_prompt[:-1]
            
            # Prompt final cu descriere de iluminare, nu obiecte
            prompt = (
                f"Romanian medieval Wallachia 1456, Vlad Tepes era, atmospheric, "
                f"dark fantasy, {llm_prompt}, highly detailed, oil-on-canvas, "
                f"warm dim lighting, soft orange glow, deep shadows, 4k, vintage parchment look"
            )
            return prompt
        except Exception as e:
            print("LLM image-prompt failed:", e)
            # Fallback la metoda veche
            return Config.generate_image_prompt(text, location)
        
    @staticmethod
    def generate_image_prompt(text: str, location: str) -> str:
        # Extragem ultimele 3 propoziÈ›ii sau primele 150 caractere
        short = " ".join(text.split(".")[-3:]).strip()
        if len(short) < 20:
            short = text[:150]

        def translate_to_english(text: str) -> str:
            """Traduce textul romÃ¢nesc Ã®n englezÄƒ pentru Stable Diffusion"""
            try:        
                return GoogleTranslator(source='ro', target='en').translate(text)
            except Exception as e:
                print(f"âš ï¸ Eroare traducere: {e}")
                return text  # Fallback la romÃ¢nÄƒ
        # **TRADUCERE Ã®n englezÄƒ**
        short_en = translate_to_english(short)
        location_en = translate_to_english(location)
        
        # Construim promptul Ã®n englezÄƒ
        prompt = (
            f"Romanian medieval Wallachia 1456, Vlad Tepes era, atmospheric, "
            f"dark fantasy, {location_en}, {short_en}, highly detailed, oil-on-canvas, "
            f"warm candle-light, 4k, vintage parchment look"
        )
        
        return prompt[:195]
    
    @staticmethod
    def generate_image_prompt_llm(text: str, location: str) -> str:
        """
        Ask the SAME Groq endpoint we use for narration to write a short
        Stable-Diffusion prompt in English, grounded in the *exact* place
        and current narrative moment.
        """
        token = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY", "")
        if not token:
            # fallback to old method if somehow no key
            return Config.generate_image_prompt(text, location)

        system = (
            "You are an assistant that writes short, highly detailed prompts "
            "for Stable-Diffusion in English. "
            "Include: time of day, number of people in the image, context, weather, "
            "camera angle and any information usefull for image generation. Keep it under 200 characters."
        )

        user = (
            f"Story fragment: {text}\n"
            f"Exact place: {location}\n"
            "Write one English Stable-Diffusion prompt."
        )

        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ],
            "temperature": 0.75,
            "max_tokens": 60,
            "stream": False
        }

        try:
            r = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {token}",
                    "Content-Type": "application/json"
                },
                json=payload,
                timeout=15
            )
            r.raise_for_status()
            llm_prompt = r.json()["choices"][0]["message"]["content"].strip()
            # ðŸ”§ CLEAN: remove quotes and trailing period
            llm_prompt = llm_prompt.replace('"', '')
            if llm_prompt.endswith('.'):
                llm_prompt = llm_prompt[:-1]
            prompt = (
            f"Romanian medieval Wallachia 1456, Vlad Tepes era, atmospheric, "
            f"dark fantasy, {llm_prompt}, highly detailed, oil-on-canvas, "
            f"warm dim lighting, deep shadows, 4k, vintage parchment look"
        )
            return prompt
        except Exception as e:
            print("LLM image-prompt failed:", e)
            # graceful fallback
            return Config.generate_image_prompt(text, location)


class ModelRouter:
    def __init__(self):
        self.api_models = Config.FALLBACK_API_MODELS.copy()
        self.api_models.insert(0, Config.PRIMARY_API_MODEL)
        self.current_api_index = 0

    def get_next_api_model(self) -> str:
        model = self.api_models[self.current_api_index]
        self.current_api_index = (self.current_api_index + 1) % len(self.api_models)
        return model